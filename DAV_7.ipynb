{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishjagwani/DAV_72/blob/main/DAV_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3PpT8onXACK"
      },
      "source": [
        "# Tokenization\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpDB2AUXXDDK",
        "outputId": "1e2e6ff0-afd2-4dce-df3a-05a2165cc2ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzbGe0J0YNkV",
        "outputId": "109ea21e-84a5-462e-d836-16cb87484dc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.15.2)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkDqFdyZYOvK",
        "outputId": "56e39c7e-1bc6-4179-f06a-237f0164213a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n",
            "['Tokenization', 'is', 'the', 'process', 'of', 'breaking', 'down', 'text', 'into', 'smaller', 'units', 'called', 'tokens', '.']\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Sample text\n",
        "text = \"Tokenization is the process of breaking down text into smaller units called tokens.\"\n",
        "\n",
        "# Tokenize the text into words\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Print the tokens\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zio4KoV5YjxJ"
      },
      "source": [
        "# Frequency Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38rZASdpYlLr"
      },
      "outputs": [],
      "source": [
        "from nltk import FreqDist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBduHj2nYnJD",
        "outputId": "c9be02bb-f1fa-41e0-ffec-3e3b526be495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('Tokenization', 1), ('is', 1), ('the', 1), ('process', 1), ('of', 1), ('breaking', 1), ('down', 1), ('text', 1), ('into', 1), ('smaller', 1), ('units', 1), ('called', 1), ('tokens', 1), ('.', 1)]\n"
          ]
        }
      ],
      "source": [
        "freq_dist = FreqDist(tokens)\n",
        "\n",
        "# Print the frequency distribution\n",
        "print(freq_dist.most_common())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ox18FvMYs8y"
      },
      "source": [
        "# Remove stopwords & punctuations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00Y8xOP3Yt77",
        "outputId": "5ec21f6d-91e3-4b97-ffdc-4720d4c1917e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvzorHD1YwNT",
        "outputId": "3cc06843-5acd-40b8-8ecb-1e998a013129"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Tokenization', 'process', 'breaking', 'text', 'smaller', 'units', 'called', 'tokens', 'important', 'natural', 'language', 'processing']\n"
          ]
        }
      ],
      "source": [
        "text = \"Tokenization is the process of breaking down text into smaller units called tokens,It is important in natural language processing.\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Remove stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "# Remove punctuation\n",
        "filtered_tokens = [word for word in filtered_tokens if word not in string.punctuation]\n",
        "\n",
        "# Print filtered tokens\n",
        "print(filtered_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9BPrdsnY3tD"
      },
      "source": [
        "# Lexicon Normalization (Stemming, Lemmatization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfmMj09QY4hK",
        "outputId": "ca9ef657-21ae-4fe0-e7cd-448cae68c8c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['run', 'runner', 'run']\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text = \"running runner runs\"\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "stems = [stemmer.stem(word) for word in tokens]\n",
        "print(stems)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1e17xSYY6dq",
        "outputId": "1ac23c94-173d-4982-d29d-6246a1e09545"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['The', 'cat', 'are', 'running', 'and', 'jumping', 'on', 'the', 'bed', '.']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download WordNet corpus if not already downloaded\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Input text\n",
        "text = \"The cats are running and jumping on the beds.\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Initialize WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Lemmatize each token\n",
        "lemmas = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "# Print the lemmatized tokens\n",
        "print(lemmas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oj8yr2c_ZKU6"
      },
      "source": [
        "# Part of Speech tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVfvKH8BZOIT",
        "outputId": "71045774-09b0-45a3-cbb0-3281c5d6151c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('The', 'DT'), ('cats', 'NNS'), ('are', 'VBP'), ('running', 'VBG'), ('and', 'CC'), ('jumping', 'VBG'), ('on', 'IN'), ('the', 'DT'), ('beds', 'NNS'), ('.', '.')]\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Perform POS tagging\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "\n",
        "# Print POS tagged tokens\n",
        "print(pos_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCEyArvKavWi",
        "outputId": "608264c1-a939-42b8-a592-6bd5e3621e8b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaXv1YZSaxtj"
      },
      "source": [
        "# Named Entity Recognization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3bDobj8aytz",
        "outputId": "15e4dafb-978a-4743-ec8d-28543c5d1249"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFtD_xcfa0YC",
        "outputId": "e618aa09-5d41-4f42-aaa5-e2bbfe33bb37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPE Apple\n",
            "GPE Cupertino\n",
            "GPE California\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Sample text\n",
        "text = \"Apple is headquartered in Cupertino, California.\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Perform Named Entity Recognition\n",
        "ne_tags = nltk.pos_tag(tokens)\n",
        "ne_chunks = nltk.ne_chunk(ne_tags)\n",
        "\n",
        "# Print Named Entities\n",
        "for chunk in ne_chunks:\n",
        "    if hasattr(chunk, 'label'):\n",
        "        print(chunk.label(), ' '.join(c[0] for c in chunk))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqtF2-kfa56s"
      },
      "source": [
        "# Scrape data from a website"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dzOSaAka6ob",
        "outputId": "13c97f51-eeff-4413-957b-5da7a68fd7b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#bodyContent\n",
            "/wiki/Main_Page\n",
            "/wiki/Wikipedia:Contents\n",
            "/wiki/Portal:Current_events\n",
            "/wiki/Special:Random\n",
            "/wiki/Wikipedia:About\n",
            "//en.wikipedia.org/wiki/Wikipedia:Contact_us\n",
            "https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en\n",
            "/wiki/Help:Contents\n",
            "/wiki/Help:Introduction\n",
            "/wiki/Wikipedia:Community_portal\n",
            "/wiki/Special:RecentChanges\n",
            "/wiki/Wikipedia:File_upload_wizard\n",
            "/wiki/Main_Page\n",
            "/wiki/Special:Search\n",
            "/w/index.php?title=Special:CreateAccount&returnto=Main+Page\n",
            "/w/index.php?title=Special:UserLogin&returnto=Main+Page\n",
            "/w/index.php?title=Special:CreateAccount&returnto=Main+Page\n",
            "/w/index.php?title=Special:UserLogin&returnto=Main+Page\n",
            "/wiki/Help:Introduction\n",
            "/wiki/Special:MyContributions\n",
            "/wiki/Special:MyTalk\n",
            "/wiki/Main_Page\n",
            "/wiki/Talk:Main_Page\n",
            "/wiki/Main_Page\n",
            "/w/index.php?title=Main_Page&action=edit\n",
            "/w/index.php?title=Main_Page&action=history\n",
            "/wiki/Main_Page\n",
            "/w/index.php?title=Main_Page&action=edit\n",
            "/w/index.php?title=Main_Page&action=history\n",
            "/wiki/Special:WhatLinksHere/Main_Page\n",
            "/wiki/Special:RecentChangesLinked/Main_Page\n",
            "/wiki/Wikipedia:File_Upload_Wizard\n",
            "/wiki/Special:SpecialPages\n",
            "/w/index.php?title=Main_Page&oldid=1212457119\n",
            "/w/index.php?title=Main_Page&action=info\n",
            "/w/index.php?title=Special:CiteThisPage&page=Main_Page&id=1212457119&wpFormIdentifier=titleform\n",
            "/w/index.php?title=Special:UrlShortener&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FMain_Page\n",
            "/w/index.php?title=Special:QrCode&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FMain_Page\n",
            "https://www.wikidata.org/wiki/Special:EntityPage/Q5296\n",
            "/w/index.php?title=Special:DownloadAsPdf&page=Main_Page&action=show-download-screen\n",
            "/w/index.php?title=Main_Page&printable=yes\n",
            "https://commons.wikimedia.org/wiki/Main_Page\n",
            "https://foundation.wikimedia.org/wiki/Home\n",
            "https://www.mediawiki.org/wiki/MediaWiki\n",
            "https://meta.wikimedia.org/wiki/Main_Page\n",
            "https://outreach.wikimedia.org/wiki/Main_Page\n",
            "https://wikisource.org/wiki/Main_Page\n",
            "https://species.wikimedia.org/wiki/Main_Page\n",
            "https://en.wikibooks.org/wiki/Main_Page\n",
            "https://www.wikidata.org/wiki/Wikidata:Main_Page\n",
            "https://www.wikifunctions.org/wiki/Wikifunctions:Main_Page\n",
            "https://wikimania.wikimedia.org/wiki/Wikimania\n",
            "https://en.wikinews.org/wiki/Main_Page\n",
            "https://en.wikiquote.org/wiki/Main_Page\n",
            "https://en.wikisource.org/wiki/Main_Page\n",
            "https://en.wikiversity.org/wiki/Wikiversity:Main_Page\n",
            "https://en.wikivoyage.org/wiki/Main_Page\n",
            "https://en.wiktionary.org/wiki/Wiktionary:Main_Page\n",
            "/wiki/Wikipedia\n",
            "/wiki/Free_content\n",
            "/wiki/Encyclopedia\n",
            "/wiki/Help:Introduction_to_Wikipedia\n",
            "/wiki/Special:Statistics\n",
            "/wiki/English_language\n",
            "/wiki/File:Bank_Note_Printing_Plant_Tower.jpg\n",
            "/wiki/American_Bank_Note_Company_Printing_Plant\n",
            "/wiki/Hunts_Point,_Bronx\n",
            "/wiki/The_Bronx\n",
            "/wiki/New_York_City\n",
            "/wiki/Kirby,_Petit_%26_Green\n",
            "/wiki/ABCorp\n",
            "/wiki/Edward_G._Faile\n",
            "/wiki/Security_(finance)\n",
            "/wiki/New_York_Stock_Exchange\n",
            "/wiki/Latin_America\n",
            "/wiki/Fuerzas_Armadas_de_Liberaci%C3%B3n_Nacional_Puertorrique%C3%B1a\n",
            "/wiki/New_York_City_Landmarks_Preservation_Commission\n",
            "/wiki/John_V._Lindsay_Wildcat_Academy_Charter_School\n",
            "/wiki/New_York_City_Human_Resources_Administration\n",
            "/wiki/American_Bank_Note_Company_Printing_Plant\n",
            "/wiki/George_Griffith\n",
            "/wiki/Attalus_I\n",
            "/wiki/Black-necked_grebe\n",
            "/wiki/Wikipedia:Today%27s_featured_article/March_2024\n",
            "https://lists.wikimedia.org/postorius/lists/daily-article-l.lists.wikimedia.org/\n",
            "/wiki/Wikipedia:Featured_articles\n",
            "/wiki/Wikipedia:About_Today%27s_featured_article\n",
            "/wiki/File:1961_Sumner_Kaplan_Massachusetts_House_of_Representatives.png\n",
            "/wiki/Brookline,_Massachusetts\n",
            "/wiki/Sumner_Z._Kaplan\n",
            "/wiki/GBI_(German_Bold_Italic)\n",
            "/wiki/Typeface\n",
            "/wiki/Madeleine_Steere\n",
            "/wiki/Tapir!\n",
            "/wiki/Papier-m%C3%A2ch%C3%A9\n",
            "/wiki/Ali_Ahmed_Karti\n",
            "/wiki/WREP-LD\n",
            "/wiki/Vampire_Weekend\n",
            "/wiki/Only_God_Was_Above_Us\n",
            "/wiki/New_York_Daily_News\n",
            "/wiki/Aloha_Airlines_Flight_243\n",
            "/wiki/Billy_Fitzgerald_(lacrosse)\n",
            "/wiki/Mule_deer\n",
            "/wiki/Juniperus_scopulorum\n",
            "/wiki/Wikipedia:Recent_additions\n",
            "/wiki/Help:Your_first_article\n",
            "/wiki/Template_talk:Did_you_know\n",
            "/wiki/File:%D0%92%D0%BB%D0%B0%D0%B4%D0%B8%D0%BC%D0%B8%D1%80_%D0%9F%D1%83%D1%82%D0%B8%D0%BD_(18-06-2023)_(cropped).jpg\n",
            "/wiki/Vladimir_Putin\n",
            "/wiki/2024_Russian_presidential_election\n",
            "/wiki/Democratic_Alliance_(Portugal,_2024)\n",
            "/wiki/2024_Portuguese_legislative_election\n",
            "/wiki/96th_Academy_Awards\n",
            "/wiki/Oppenheimer_(film)\n",
            "/wiki/Academy_Award_for_Best_Picture\n",
            "/wiki/Manga\n",
            "/wiki/Akira_Toriyama\n",
            "/wiki/Dragon_Ball\n",
            "/wiki/Portal:Current_events\n",
            "/wiki/Israel%E2%80%93Hamas_war\n",
            "/wiki/Myanmar_civil_war_(2021%E2%80%93present)\n",
            "/wiki/Red_Sea_crisis\n",
            "/wiki/Russian_invasion_of_Ukraine\n",
            "/wiki/Timeline_of_the_Russian_invasion_of_Ukraine_(1_December_2023_%E2%80%93_present)\n",
            "/wiki/Deaths_in_2024\n",
            "/wiki/Aribert_Reimann\n",
            "/wiki/Kim_Rudd\n",
            "/wiki/Ira_Millstein\n",
            "/wiki/Bill_Plummer\n",
            "/wiki/Eric_Carmen\n",
            "/wiki/Dorie_Ladner\n",
            "/wiki/Wikipedia:In_the_news/Candidates\n",
            "/wiki/March_20\n",
            "/wiki/File:Zidovudine-3D-balls.png\n",
            "/wiki/1724\n",
            "/wiki/Pope_Innocent_XIII\n",
            "/wiki/1724_papal_conclave\n",
            "/wiki/Rome\n",
            "/wiki/1861\n",
            "/wiki/1861_Mendoza_earthquake\n",
            "/wiki/Mendoza_Province\n",
            "/wiki/Mendoza,_Argentina\n",
            "/wiki/1922\n",
            "/wiki/United_States_Navy\n",
            "/wiki/Aircraft_carrier\n",
            "/wiki/USS_Langley_(CV-1)\n",
            "/wiki/1944\n",
            "/wiki/World_War_II\n",
            "/wiki/United_States_Marine_Corps\n",
            "/wiki/Landing_on_Emirau\n",
            "/wiki/Bismarck_Archipelago\n",
            "/wiki/Operation_Cartwheel\n",
            "/wiki/1987\n",
            "/wiki/Antiviral_drug\n",
            "/wiki/Zidovudine\n",
            "/wiki/Food_and_Drug_Administration\n",
            "/wiki/HIV/AIDS\n",
            "/wiki/2014\n",
            "/wiki/Taliban\n",
            "/wiki/2014_Kabul_Serena_Hotel_shooting\n",
            "/wiki/Kabul_Serena_Hotel\n",
            "/wiki/Maud_Menten\n",
            "/wiki/Willie_Brown_(politician)\n",
            "/wiki/Fernando_Torres\n",
            "/wiki/Christel_Boom\n",
            "/wiki/March_19\n",
            "/wiki/March_20\n",
            "/wiki/March_21\n",
            "/wiki/Wikipedia:Selected_anniversaries/March\n",
            "https://lists.wikimedia.org/postorius/lists/daily-article-l.lists.wikimedia.org/\n",
            "/wiki/List_of_days_of_the_year\n",
            "/wiki/File:Schopfkarakara.jpg\n",
            "/wiki/Crested_caracara\n",
            "/wiki/Bird_of_prey\n",
            "/wiki/Falconidae\n",
            "/wiki/Minnesota\n",
            "/wiki/Tierra_del_Fuego\n",
            "/wiki/Serra_da_Canastra_National_Park\n",
            "/wiki/User:Merops\n",
            "/wiki/Template:POTD/2024-03-19\n",
            "/wiki/Template:POTD/2024-03-18\n",
            "/wiki/Template:POTD/2024-03-17\n",
            "/wiki/Wikipedia:Picture_of_the_day/Archive\n",
            "/wiki/Wikipedia:Featured_pictures\n",
            "/wiki/Wikipedia:Community_portal\n",
            "/wiki/Wikipedia:Village_pump\n",
            "/wiki/Wikipedia:News\n",
            "/wiki/Wikipedia:Teahouse\n",
            "/wiki/Wikipedia:Help_desk\n",
            "/wiki/Wikipedia:Reference_desk\n",
            "/wiki/Wikipedia:Contents/Portals\n",
            "/wiki/Wikimedia_Foundation\n",
            "https://wikimediafoundation.org/our-work/wikimedia-projects/\n",
            "https://commons.wikimedia.org/wiki/\n",
            "https://commons.wikimedia.org/wiki/\n",
            "https://www.mediawiki.org/wiki/\n",
            "https://www.mediawiki.org/wiki/\n",
            "https://meta.wikimedia.org/wiki/\n",
            "https://meta.wikimedia.org/wiki/\n",
            "https://en.wikibooks.org/wiki/\n",
            "https://en.wikibooks.org/wiki/\n",
            "https://www.wikidata.org/wiki/\n",
            "https://www.wikidata.org/wiki/\n",
            "https://en.wikinews.org/wiki/\n",
            "https://en.wikinews.org/wiki/\n",
            "https://en.wikiquote.org/wiki/\n",
            "https://en.wikiquote.org/wiki/\n",
            "https://en.wikisource.org/wiki/\n",
            "https://en.wikisource.org/wiki/\n",
            "https://species.wikimedia.org/wiki/\n",
            "https://species.wikimedia.org/wiki/\n",
            "https://en.wikiversity.org/wiki/\n",
            "https://en.wikiversity.org/wiki/\n",
            "https://en.wikivoyage.org/wiki/\n",
            "https://en.wikivoyage.org/wiki/\n",
            "https://en.wiktionary.org/wiki/\n",
            "https://en.wiktionary.org/wiki/\n",
            "/wiki/English_language\n",
            "https://meta.wikimedia.org/wiki/List_of_Wikipedias\n",
            "https://ar.wikipedia.org/wiki/\n",
            "https://arz.wikipedia.org/wiki/\n",
            "https://de.wikipedia.org/wiki/\n",
            "https://es.wikipedia.org/wiki/\n",
            "https://fr.wikipedia.org/wiki/\n",
            "https://it.wikipedia.org/wiki/\n",
            "https://nl.wikipedia.org/wiki/\n",
            "https://ja.wikipedia.org/wiki/\n",
            "https://pl.wikipedia.org/wiki/\n",
            "https://pt.wikipedia.org/wiki/\n",
            "https://ru.wikipedia.org/wiki/\n",
            "https://sv.wikipedia.org/wiki/\n",
            "https://uk.wikipedia.org/wiki/\n",
            "https://vi.wikipedia.org/wiki/\n",
            "https://zh.wikipedia.org/wiki/\n",
            "https://id.wikipedia.org/wiki/\n",
            "https://ms.wikipedia.org/wiki/\n",
            "https://zh-min-nan.wikipedia.org/wiki/\n",
            "https://bg.wikipedia.org/wiki/\n",
            "https://ca.wikipedia.org/wiki/\n",
            "https://cs.wikipedia.org/wiki/\n",
            "https://da.wikipedia.org/wiki/\n",
            "https://eo.wikipedia.org/wiki/\n",
            "https://eu.wikipedia.org/wiki/\n",
            "https://fa.wikipedia.org/wiki/\n",
            "https://he.wikipedia.org/wiki/\n",
            "https://hy.wikipedia.org/wiki/\n",
            "https://ko.wikipedia.org/wiki/\n",
            "https://hu.wikipedia.org/wiki/\n",
            "https://no.wikipedia.org/wiki/\n",
            "https://ro.wikipedia.org/wiki/\n",
            "https://sr.wikipedia.org/wiki/\n",
            "https://sh.wikipedia.org/wiki/\n",
            "https://fi.wikipedia.org/wiki/\n",
            "https://tr.wikipedia.org/wiki/\n",
            "https://ast.wikipedia.org/wiki/\n",
            "https://bn.wikipedia.org/wiki/\n",
            "https://bs.wikipedia.org/wiki/\n",
            "https://ckb.wikipedia.org/wiki/\n",
            "https://et.wikipedia.org/wiki/\n",
            "https://el.wikipedia.org/wiki/\n",
            "https://simple.wikipedia.org/wiki/\n",
            "https://fy.wikipedia.org/wiki/\n",
            "https://ga.wikipedia.org/wiki/\n",
            "https://gl.wikipedia.org/wiki/\n",
            "https://hr.wikipedia.org/wiki/\n",
            "https://ka.wikipedia.org/wiki/\n",
            "https://ku.wikipedia.org/wiki/\n",
            "https://lv.wikipedia.org/wiki/\n",
            "https://lt.wikipedia.org/wiki/\n",
            "https://ml.wikipedia.org/wiki/\n",
            "https://mk.wikipedia.org/wiki/\n",
            "https://my.wikipedia.org/wiki/\n",
            "https://nn.wikipedia.org/wiki/\n",
            "https://pa.wikipedia.org/wiki/\n",
            "https://sq.wikipedia.org/wiki/\n",
            "https://sk.wikipedia.org/wiki/\n",
            "https://sl.wikipedia.org/wiki/\n",
            "https://th.wikipedia.org/wiki/\n",
            "https://te.wikipedia.org/wiki/\n",
            "https://ur.wikipedia.org/wiki/\n",
            "https://uz.wikipedia.org/wiki/\n",
            "https://en.wikipedia.org/w/index.php?title=Main_Page&oldid=1212457119\n",
            "https://ar.wikipedia.org/wiki/\n",
            "https://bn.wikipedia.org/wiki/\n",
            "https://bg.wikipedia.org/wiki/\n",
            "https://bs.wikipedia.org/wiki/\n",
            "https://ca.wikipedia.org/wiki/\n",
            "https://cs.wikipedia.org/wiki/\n",
            "https://da.wikipedia.org/wiki/\n",
            "https://de.wikipedia.org/wiki/\n",
            "https://et.wikipedia.org/wiki/\n",
            "https://el.wikipedia.org/wiki/\n",
            "https://es.wikipedia.org/wiki/\n",
            "https://eo.wikipedia.org/wiki/\n",
            "https://eu.wikipedia.org/wiki/\n",
            "https://fa.wikipedia.org/wiki/\n",
            "https://fr.wikipedia.org/wiki/\n",
            "https://gl.wikipedia.org/wiki/\n",
            "https://ko.wikipedia.org/wiki/\n",
            "https://hr.wikipedia.org/wiki/\n",
            "https://id.wikipedia.org/wiki/\n",
            "https://it.wikipedia.org/wiki/\n",
            "https://he.wikipedia.org/wiki/\n",
            "https://ka.wikipedia.org/wiki/\n",
            "https://lv.wikipedia.org/wiki/\n",
            "https://lt.wikipedia.org/wiki/\n",
            "https://hu.wikipedia.org/wiki/\n",
            "https://mk.wikipedia.org/wiki/\n",
            "https://ms.wikipedia.org/wiki/\n",
            "https://nl.wikipedia.org/wiki/\n",
            "https://ja.wikipedia.org/wiki/\n",
            "https://no.wikipedia.org/wiki/\n",
            "https://nn.wikipedia.org/wiki/\n",
            "https://pl.wikipedia.org/wiki/\n",
            "https://pt.wikipedia.org/wiki/\n",
            "https://ro.wikipedia.org/wiki/\n",
            "https://ru.wikipedia.org/wiki/\n",
            "https://simple.wikipedia.org/wiki/\n",
            "https://sk.wikipedia.org/wiki/\n",
            "https://sl.wikipedia.org/wiki/\n",
            "https://ckb.wikipedia.org/wiki/\n",
            "https://sr.wikipedia.org/wiki/\n",
            "https://sh.wikipedia.org/wiki/\n",
            "https://fi.wikipedia.org/wiki/\n",
            "https://sv.wikipedia.org/wiki/\n",
            "https://th.wikipedia.org/wiki/\n",
            "https://tr.wikipedia.org/wiki/\n",
            "https://uk.wikipedia.org/wiki/\n",
            "https://vi.wikipedia.org/wiki/\n",
            "https://zh.wikipedia.org/wiki/\n",
            "//en.wikipedia.org/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License\n",
            "//en.wikipedia.org/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License\n",
            "//foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Terms_of_Use\n",
            "//foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy\n",
            "//www.wikimediafoundation.org/\n",
            "https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy\n",
            "/wiki/Wikipedia:About\n",
            "/wiki/Wikipedia:General_disclaimer\n",
            "//en.wikipedia.org/wiki/Wikipedia:Contact_us\n",
            "https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Universal_Code_of_Conduct\n",
            "https://developer.wikimedia.org\n",
            "https://stats.wikimedia.org/#/en.wikipedia.org\n",
            "https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Cookie_statement\n",
            "//en.m.wikipedia.org/w/index.php?title=Main_Page&mobileaction=toggle_view_mobile\n",
            "https://wikimediafoundation.org/\n",
            "https://www.mediawiki.org/\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL of the website to scrape\n",
        "url = \"https://en.wikipedia.org/wiki/Main_Page\"\n",
        "\n",
        "# Send a GET request to the URL\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful (status code 200)\n",
        "if response.status_code == 200:\n",
        "    # Parse the HTML content of the webpage\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Find and extract the desired data from the webpage\n",
        "    # For example, if you want to scrape all the links on the webpage:\n",
        "    links = soup.find_all('a')\n",
        "\n",
        "    # Print the extracted links\n",
        "    for link in links:\n",
        "        print(link.get('href'))\n",
        "else:\n",
        "    print('Failed to retrieve the webpage. Status code:', response.status_code)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krEOiMA3dVL7"
      },
      "source": [
        "## Using R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5ySW_L-dYHy",
        "outputId": "99aef984-5049-43c1-f10f-565a6844980f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘NLP’, ‘Rcpp’, ‘slam’, ‘BH’\n",
            "\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependency ‘SnowballC’\n",
            "\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘openNLPdata’, ‘rJava’\n",
            "\n",
            "\n",
            "Warning message in install.packages(\"openNLP\"):\n",
            "“installation of package ‘rJava’ had non-zero exit status”\n",
            "Warning message in install.packages(\"openNLP\"):\n",
            "“installation of package ‘openNLPdata’ had non-zero exit status”\n",
            "Warning message in install.packages(\"openNLP\"):\n",
            "“installation of package ‘openNLP’ had non-zero exit status”\n"
          ]
        }
      ],
      "source": [
        "install.packages(\"tm\")\n",
        "install.packages(\"rvest\")\n",
        "install.packages(\"tokenizers\")\n",
        "install.packages(\"openNLP\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10vtDqVLde8R"
      },
      "outputs": [],
      "source": [
        "library(tm)\n",
        "library(rvest)\n",
        "library(NLP)\n",
        "library(tokenizers)\n",
        "library(SnowballC)\n",
        "#library(openNLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0lDqakZdjiT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc6c532b-533c-42c2-d3d9-604239844fda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence Tokens: He raced to the grocery store. He went inside but realized he forgot his wallet. He raced back home to grab it. Once he found it, he raced to the car again and drove the Ushers. \n",
            "Word Tokens: he raced to the grocery store he went inside but realized he forgot his wallet he raced back home to grab it once he found it he raced to the car again and drove the ushers \n",
            "\n",
            "   he raced \n",
            "    6     3 \n"
          ]
        }
      ],
      "source": [
        "text <- \"He raced to the grocery store. He went inside but realized he forgot his wallet. He raced back home to grab it. Once he found it, he raced to the car again and drove the Ushers.\"\n",
        "sent_tokens <- unlist(tokenize_sentences(text))\n",
        "word_tokens <- unlist(tokenize_words(text))\n",
        "cat(\"Sentence Tokens:\", sent_tokens, \"\\n\")\n",
        "cat(\"Word Tokens:\", word_tokens, \"\\n\")\n",
        "# Frequency Distribution\n",
        "fdist <- table(unlist(word_tokens))\n",
        "print(head(sort(fdist, decreasing = TRUE), 2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove stopwords and punctuations\n",
        "stop_words <- stopwords(\"en\")\n",
        "filtered_tokens <- word_tokens[!(word_tokens %in% stop_words) & grepl(\"[a-zA-Z]\", word_tokens)]\n",
        "cat(\"Filtered Tokens (without stopwords and punctuations):\", filtered_tokens, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xu57KWqe7JS",
        "outputId": "c4116212-e8e4-4de0-84a1-da8e128d0f48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered Tokens (without stopwords and punctuations): raced grocery store went inside realized forgot wallet raced back home grab found raced car drove ushers \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming\n",
        "stemmed_tokens <- wordStem(filtered_tokens, language = \"en\")\n",
        "\n",
        "# Lemmatization\n",
        "lemmatized_text <- tolower(text)\n",
        "lemmatized_text <- wordStem(lemmatized_text, language = \"en\")\n",
        "cat(\"Stemmed Tokens:\", stemmed_tokens, \"\\n\")\n",
        "cat(\"Lemmatized Text:\", lemmatized_text, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEJEmni2e7si",
        "outputId": "9b77129f-9d45-4348-bb81-71d8bb0c34d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemmed Tokens: race groceri store went insid realiz forgot wallet race back home grab found race car drove usher \n",
            "Lemmatized Text: he raced to the grocery store. he went inside but realized he forgot his wallet. he raced back home to grab it. once he found it, he raced to the car again and drove the ushers. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Web Scraping\n",
        "url <- 'http://quotes.toscrape.com/'\n",
        "web_page <- read_html(url)\n",
        "web_text <- html_text(web_page)\n",
        "cat(\"Scraped Data from the Website:\\n\", web_text)"
      ],
      "metadata": {
        "id": "09TTott9e-JD",
        "outputId": "71dae3c9-cead-4dab-ed28-61b0a844f6c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraped Data from the Website:\n",
            " Quotes to Scrape\n",
            "    \n",
            "        \n",
            "            \n",
            "                \n",
            "                    Quotes to Scrape\n",
            "                \n",
            "            \n",
            "            \n",
            "                \n",
            "                \n",
            "                    Login\n",
            "                \n",
            "                \n",
            "            \n",
            "        \n",
            "    \n",
            "\n",
            "\n",
            "    \n",
            "\n",
            "    \n",
            "        “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
            "        by Albert Einstein\n",
            "        (about)\n",
            "        \n",
            "        \n",
            "            Tags:\n",
            "            change\n",
            "            \n",
            "            deep-thoughts\n",
            "            \n",
            "            thinking\n",
            "            \n",
            "            world\n",
            "            \n",
            "        \n",
            "    \n",
            "\n",
            "    \n",
            "        “It is our choices, Harry, that show what we truly are, far more than our abilities.”\n",
            "        by J.K. Rowling\n",
            "        (about)\n",
            "        \n",
            "        \n",
            "            Tags:\n",
            "            abilities\n",
            "            \n",
            "            choices\n",
            "            \n",
            "        \n",
            "    \n",
            "\n",
            "    \n",
            "        “There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\n",
            "        by Albert Einstein\n",
            "        (about)\n",
            "        \n",
            "        \n",
            "            Tags:\n",
            "            inspirational\n",
            "            \n",
            "            life\n",
            "            \n",
            "            live\n",
            "            \n",
            "            miracle\n",
            "            \n",
            "            miracles\n",
            "            \n",
            "        \n",
            "    \n",
            "\n",
            "    \n",
            "        “The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n",
            "        by Jane Austen\n",
            "        (about)\n",
            "        \n",
            "        \n",
            "            Tags:\n",
            "            aliteracy\n",
            "            \n",
            "            books\n",
            "            \n",
            "            classic\n",
            "            \n",
            "            humor\n",
            "            \n",
            "        \n",
            "    \n",
            "\n",
            "    \n",
            "        “Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\n",
            "        by Marilyn Monroe\n",
            "        (about)\n",
            "        \n",
            "        \n",
            "            Tags:\n",
            "            be-yourself\n",
            "            \n",
            "            inspirational\n",
            "            \n",
            "        \n",
            "    \n",
            "\n",
            "    \n",
            "        “Try not to become a man of success. Rather become a man of value.”\n",
            "        by Albert Einstein\n",
            "        (about)\n",
            "        \n",
            "        \n",
            "            Tags:\n",
            "            adulthood\n",
            "            \n",
            "            success\n",
            "            \n",
            "            value\n",
            "            \n",
            "        \n",
            "    \n",
            "\n",
            "    \n",
            "        “It is better to be hated for what you are than to be loved for what you are not.”\n",
            "        by André Gide\n",
            "        (about)\n",
            "        \n",
            "        \n",
            "            Tags:\n",
            "            life\n",
            "            \n",
            "            love\n",
            "            \n",
            "        \n",
            "    \n",
            "\n",
            "    \n",
            "        “I have not failed. I've just found 10,000 ways that won't work.”\n",
            "        by Thomas A. Edison\n",
            "        (about)\n",
            "        \n",
            "        \n",
            "            Tags:\n",
            "            edison\n",
            "            \n",
            "            failure\n",
            "            \n",
            "            inspirational\n",
            "            \n",
            "            paraphrased\n",
            "            \n",
            "        \n",
            "    \n",
            "\n",
            "    \n",
            "        “A woman is like a tea bag; you never know how strong it is until it's in hot water.”\n",
            "        by Eleanor Roosevelt\n",
            "        (about)\n",
            "        \n",
            "        \n",
            "            Tags:\n",
            "            misattributed-eleanor-roosevelt\n",
            "            \n",
            "        \n",
            "    \n",
            "\n",
            "    \n",
            "        “A day without sunshine is like, you know, night.”\n",
            "        by Steve Martin\n",
            "        (about)\n",
            "        \n",
            "        \n",
            "            Tags:\n",
            "            humor\n",
            "            \n",
            "            obvious\n",
            "            \n",
            "            simile\n",
            "            \n",
            "        \n",
            "    \n",
            "\n",
            "    \n",
            "                Next →\n",
            "            \n",
            "            \n",
            "        \n",
            "    \n",
            "        \n",
            "            Top Ten tags\n",
            "            \n",
            "            \n",
            "            love\n",
            "            \n",
            "            \n",
            "            \n",
            "            inspirational\n",
            "            \n",
            "            \n",
            "            \n",
            "            life\n",
            "            \n",
            "            \n",
            "            \n",
            "            humor\n",
            "            \n",
            "            \n",
            "            \n",
            "            books\n",
            "            \n",
            "            \n",
            "            \n",
            "            reading\n",
            "            \n",
            "            \n",
            "            \n",
            "            friendship\n",
            "            \n",
            "            \n",
            "            \n",
            "            friends\n",
            "            \n",
            "            \n",
            "            \n",
            "            truth\n",
            "            \n",
            "            \n",
            "            \n",
            "            simile\n",
            "            \n",
            "            \n",
            "        \n",
            "    \n",
            "\n",
            "\n",
            "    \n",
            "    \n",
            "            \n",
            "                Quotes by: GoodReads.com\n",
            "            \n",
            "            \n",
            "                Made with ❤ by Zyte\n",
            "            \n",
            "        \n",
            "    "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZLfWwiJ4e_vS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNWQIR4ilBeNkzCfZ0oCrA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}